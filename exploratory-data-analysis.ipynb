{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corporate Credit Rating Dataset: Exploratory Data Analysis and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  [Corporate Credit Rating](https://www.kaggle.com/datasets/agewerc/corporate-credit-rating/data) dataset is obtained from Kaggle ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from .csv file \n",
    "ratings_df = pd.read_csv('./raw_corporate_rating.csv')\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset `ratings_df` consists of 2029 entries (rows) and 31 columns. Each entry represents a big US firm traded on NYSE or Nasdaq. The ratings span the period from 2010 to 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of entries, names of the columns and data types\n",
    "ratings_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has 593 unique US firms, as seen from `ratings_df.Name.value_counts()`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df.Name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit Ratings\n",
    "\n",
    "The target variable is the `Rating` column, representing the credit rating assigned by agencies. Credit ratings categorize a company's ability to repay debt. Taking a closer look at the list of agencies and their different ratings using `ratings_df['Rating Agency Name'].value_counts()` and `ratings_df.groupby('Rating Agency Name')['Rating'].unique()`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of Rating Agency Names\n",
    "ratings_df['Rating Agency Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the different Rating Agencies and the list of Ratings they provide\n",
    "ratings_df.groupby('Rating Agency Name')['Rating'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset shows an imbalance in credit ratings, with varying frequencies for each rating category as it is evident from `ratings_df.Rating.value_counts()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the different types of Ratings and their counts\n",
    "ratings_df.Rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot unique ratings by agency\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(x='Rating', hue='Rating Agency Name', data=ratings_df)\n",
    "plt.title('Unique Ratings by Agency')\n",
    "\n",
    "# Plot overall distribution of ratings\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.countplot(x='Rating', data=ratings_df, order=ratings_df['Rating'].value_counts().index)\n",
    "plt.title('Overall Distribution of Ratings')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Address Imbalance in the Data\n",
    "## Simplify and merge labels\n",
    "It is also important to note that we are working with ratings from different agencies. One way to address this is to simplify and merge the ratings labels according to the following table from [Investopedia: Corporate Credit Ratings](https://www.investopedia.com/terms/c/corporate-credit-rating.asp)\n",
    "| Moody's     | Standard & Poor's |  Fitch            |   Grade      | Risk         |\n",
    "|-------------|-------------------|-------------------|--------------|--------------|\n",
    "| Aaa         | AAA               | AAA               | Investment   | Lowest Risk  |\n",
    "| Aa          | AA                | AA                | Investment   | Low Risk     |\n",
    "| A           | A                 | A                 | Investment   | Low Risk     |\n",
    "| Baa         | BBB               | BBB               | Investment   | Medium Risk  |\n",
    "| Ba, B       | BB, B             | BB, B             | Junk         | High Risk    |\n",
    "| Caa/Ca      | CCC/CC/C          | CCC/CC/C          | Junk         | Highest Risk |\n",
    "| C           | D                 | D                 | Junk         | In Default   |\n",
    "\n",
    "Instead of 10 different rating categories, we have now 6 categories. \n",
    "Using a dictionary for the mapping of new ratings and old ratings and `ratings_df['Rating'].map(rating_dict)` , we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_dict = {'AAA':'Lowest Risk', \n",
    "               'AA':'Low Risk',\n",
    "               'A':'Low Risk',\n",
    "               'BBB':'Medium Risk', \n",
    "               'BB':'High Risk',\n",
    "               'B':'High Risk',\n",
    "               'CCC':'Highest Risk', \n",
    "               'CC':'Highest Risk',\n",
    "               'C':'Highest Risk',\n",
    "               'D':'In Default'}\n",
    "\n",
    "ratings_df.Rating = ratings_df.Rating.map(rating_dict)\n",
    "ratings_df.Rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 4))\n",
    "sns.countplot(x='Rating', data=ratings_df, order=ratings_df['Rating'].value_counts().index)\n",
    "plt.title('Distribution of New Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter data\n",
    "\n",
    "The rows with the Ratings: `'Lowest Risk` and `'In Default` are dropped from the dataset given their small value counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = ratings_df[ratings_df['Rating']!='Lowest Risk'] # filter Lowest Risk\n",
    "ratings_df = ratings_df[ratings_df['Rating']!='In Default']  # filter In Default\n",
    "ratings_df.reset_index(inplace = True, drop=True) # reset index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although improved, our dataset still remains unbalanced.  To tackle this, SMOTE Analysis can be applied, after splitting data for train and test, to generate synthetic instances for the minority classes using the `SMOTE` function from the `imblearn.over_sampling`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Features:\n",
    "The other columns in the dataset are the input features related to financial indicators and information about the company. \n",
    "\n",
    "The 5 features with the company information such as `Name`, `Symbol` (for trading), `Rating Agency Name`, `Date`, and `Sector` provide context and additional details for analysis but their inclusion in the model may not be necessary for the specific task of credit rating prediction.  Different sectors exhibit distinct economic characteristics and respond differently to market conditions. By incorporating the `Sector` variable, we aim to enhance the granularity of our analysis, ensuring that the machine learning model discerns sector-specific trends and challenges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the Columns we don't want in our model input data\n",
    "\n",
    "columns_to_drop = [ 'Name', 'Symbol', 'Rating Agency Name' ,'Date']\n",
    "ratings_df = ratings_df.drop(columns=columns_to_drop)\n",
    "ratings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode categorical data\n",
    "\n",
    "The categorical variables `Rating` and`Sector` are converted into numerical labels using the `LabelEncoder` from scikit-learn's preprocessing module, assigning a distinct integer code to each unique label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# encode Rating\n",
    "le.fit(ratings_df.Rating)\n",
    "ratings_df.Rating = le.transform(ratings_df.Rating) \n",
    "\n",
    "# encode Sector\n",
    "le.fit(ratings_df.Sector)\n",
    "ratings_df.Sector = le.transform(ratings_df.Sector) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Features\n",
    "\n",
    "The dataset includes 25 financial indicators that can be categorized into different groups. These financial indicators collectively provide a comprehensive view of a company's financial health and performance, contributing to the evaluation of its creditworthiness.\n",
    "\n",
    "**(I) Liquidity Measurement Ratios:** These ratios provide insights into a company's short-term financial health and ability to meet its immediate obligations.\n",
    "1. `currentRatio`: Indicates the company's ability to cover short-term liabilities with short-term assets.\n",
    "2. `quickRatio`: Measures the company's ability to cover immediate liabilities without relying on inventory.\n",
    "3. `cashRatio`: Reflects the proportion of cash and cash equivalents to current liabilities.\n",
    "4. `daysOfSalesOutstanding`: Measures the average number of days it takes for a company to collect payment after a sale.\n",
    "\n",
    "**(II). Profitability Indicator Ratios:** These ratios evaluate a company's ability to generate profits relative to its revenue and investments.\n",
    "\n",
    "5. `netProfitMargin`: Represents the percentage of profit relative to total revenue.\n",
    "6. `pretaxProfitMargin`: Measures profitability before taxes are considered.\n",
    "7. `grossProfitMargin`: Indicates the percentage of revenue retained after deducting the cost of goods sold.\n",
    "8. `operatingProfitMargin`: Reflects the company's profitability from its core operations.\n",
    "9. `returnOnAssets`: Gauges how efficiently a company utilizes its assets to generate earnings.\n",
    "10. `returnOnEquity`: Measures the return generated on shareholders' equity.\n",
    "11. `returnOnCapitalEmployed`: Assesses the efficiency of capital utilization in generating profits.\n",
    "12. `ebitPerRevenue`: Measures earnings before interest and taxes relative to revenue.\n",
    "\n",
    "**(III) Debt Ratios:** These ratios assess the company's leverage and debt management.\n",
    "\n",
    "13. `debtEquityRatio`: Measures the proportion of debt relative to equity.\n",
    "14. `debtRatio` : Represents the percentage of a company's assets financed by debt.\n",
    "\n",
    "**(IV) Operating Performance Ratios:** These ratios focus on operational efficiency and effectiveness.\n",
    "\n",
    "15. `assetTurnover`: Evaluates how efficiently a company utilizes its assets to generate sales revenue.\n",
    "16. `fixedAssetTurnover` : Measures the efficiency of generating sales from fixed assets.\n",
    "17. `payablesTurnover`: Measures the efficiency of a company's payment of its liabilities.\n",
    "\n",
    "**(V) Cash Flow Indicator Ratios:** These ratios delve into a company's cash flow dynamics, providing insights into its financial sustainability. \n",
    "\n",
    "18. `operatingCashFlowPerShare`: Reflects the cash generated by core business operations per share.\n",
    "19. `freeCashFlowPerShare`: Measures the amount of cash available to shareholders after covering operational expenses and capital expenditures.\n",
    "20. `cashPerShare`: Represents the amount of cash available per outstanding share.\n",
    "21. `operatingCashFlowSalesRatio`: Evaluates the percentage of sales revenue converted into cash from operating activities.\n",
    "22. `freeCashFlowOperatingCashFlowRatio`: Measures the efficiency of converting operating cash flow into free cash flow.\n",
    "23. `effectiveTaxRate`: Reflects the company's tax efficiency.\n",
    "24. `companyEquityMultiplier`: Indicates the multiplier effect on equity due to debt\n",
    "25. `enterpriseValueMultiple`: Evaluates a company's overall value relative to its earnings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Statistics\n",
    "\n",
    "The `describe()` function gives statistical descriptions like `mean`, `min`, `max`, `percentiles` of the numerical financial indicators. Comparison of the mean to the median and examining the range between percentiles, there seems to be an indication of the presence of outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "correlation_matrix = ratings_df.iloc[:,1:].corr()\n",
    "\n",
    "# Plot the correlation matrix as a heatmap\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".1f\")\n",
    "plt.title(\"Correlation Matrix of Input Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few points can be understood from the correlation matrix:\n",
    "\n",
    "- Companies with higher Return on Equity tend to also have higher Asset Turnover and Fixed Asset Turnover, indicating that they efficiently use their assets, both overall and fixed assets, to generate profits.\n",
    "\n",
    "- A negative correlation between Return on Equity, Asset Turnover, and Fixed Asset Turnover with Return on Assets suggests a trade-off or inverse relationship. It may indicate that companies with high Return on Equity, efficient Asset Turnover, and effective use of Fixed Assets might not be as focused on maximizing profits from their total assets. Companies might be prioritizing shareholder returns (ROE) and operational efficiency (Asset Turnover, Fixed Asset Turnover) over maximizing profits from the entire asset base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize the data\n",
    "\n",
    "Features exhibit different scales, as evident from the magnitude of mean and standard deviation values. To ensure equal contribution from all features for machine learning algorithms, feature scaling is performed. The Min-Max scaling technique is applied to normalize the numerical values representing financial indicators. \n",
    "\n",
    "> $x_{scaled} = \\frac{x - x_{min}}{x_{max} - x_{min}}$\n",
    "\n",
    "For each column, the `MinMaxScaler` function from `sklearn.preprocessing` is used to transform the values into a standardized range between 0 and 1. The values are then multiplied by 1000, to amplify the scaled values. \n",
    "\n",
    "Additionally, a logarithmic transformation is applied to each value using the `np.log10` function, with a small constant (0.01) added to avoid issues with zero values. This dual transformation approach aims to normalize and potentially enhance the interpretability of the financial indicators in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "for c in ratings_df.columns[2:27]:\n",
    "\n",
    "    ratings_df[[c]] = min_max_scaler.fit_transform(ratings_df[[c]].to_numpy())*1000\n",
    "    ratings_df[[c]] = ratings_df[[c]].apply(lambda x: np.log10(x+0.01))\n",
    "\n",
    "ratings_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df.to_csv('input_corporate_rating.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This work in exploring and preparing our dataset, sets the stage for the next phase: deploying different machine learning models to forecast credit ratings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
